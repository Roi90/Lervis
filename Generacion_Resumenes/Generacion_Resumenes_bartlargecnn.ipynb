{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generacion de resumenes mediante bart-large-cnn\n",
    "\n",
    "- El codigo ha sido extraido de: https://huggingface.co/facebook/bart-large-cnn\n",
    "- El codigo ha sido extraido de: https://huggingface.co/google/bigbird-pegasus-large-arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera prueba mediante el pipeline de transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo extraido del notebook DOCLING_IBM\n",
    "txt = \"\"\" We introduce Florence-2 , a novel vision foundation model with a unified, prompt-based representation for a variety of computer vision and \n",
    "vision-language tasks. While existing large vision models excel in transfer learning, they struggle to perform a diversity of tasks with simple instructions,\n",
    "a capability that implies handling the complexity of various spatial hierarchy and semantic granularity. Florence-2 was designed to take text-prompt as task\n",
    "instructions and generate desirable results in text forms, whether it be captioning, object detection, grounding or segmentation. This multi-task learning\n",
    "setup demands largescale, high-quality annotated data. To this end, we codeveloped FLD-5B that consists of 5.4 billion comprehensive visual annotations\n",
    "on 126 million images, using an iterative strategy of automated image annotation and model refinement. We adopted a sequence-to-sequence structure to \n",
    "train Florence-2 to perform versatile and comprehensive vision tasks. Extensive evaluations on numerous tasks demonstrated Florence-2 to be a strong vision \n",
    "foundation model contender with unprecedented zero-shot and fine-tuning capabilities.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leo el archivo generado en el otro notebook\n",
    "with open(r\"..\\Segmentacion_PDF\\texto_para_resumen.txt\", \"r\", encoding=\"utf-8\") as archivo:\n",
    "    texto_grande = archivo.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bart-large-cnn - Numero de tokens 1024 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# utilizo la API de hugginface para cargar el modelo\n",
    "summarizer_bart = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0)\n",
    "tokenizer_bart = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tokens: 22281\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer_bart.encode(texto_grande)\n",
    "print(f\"Número de tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Florence-2 is a novel vision foundation model with a unified, prompt-based representation for a variety of computer vision and vision-language tasks. Florence-2 was designed to take text-prompt as task instructions and generate desirable results in text forms. This multi-task learningsetup demands largescale, high-quality annotated data.\n"
     ]
    }
   ],
   "source": [
    "resumen = summarizer_bart(txt,max_length=200, min_length=30, do_sample=False)[0]['summary_text']\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge 1\n",
      "\tPrecision : 0.96\n",
      "\tRecall : 0.29\n",
      "\tF1 Score : 0.45\n",
      "Rouge 2\n",
      "\tPrecision : 0.88\n",
      "\tRecall : 0.27\n",
      "\tF1 Score : 0.41\n",
      "Rouge L\n",
      "\tPrecision : 0.96\n",
      "\tRecall : 0.29\n",
      "\tF1 Score : 0.45\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion del resumen con mediante ROUGE\n",
    "\n",
    "# Generamos el objeto con las 3 mmetricas:\n",
    "    # Rouge 1: Evalua la coincidencia de unigramas (palabras individuales), midiendo cuántas palabras del resumen aparecen en el texto original.\n",
    "    # Rouge 2: Evalua la coincidencia de bigramas (pares de palabras consecutivas), midiendo cuantos pares de palabras del resumen se encuentran en el texto original.\n",
    "    # Rouge L: Evalúa la coincidencia de la subsecuencia común más larga, que es la secuencia más larga de palabras que aparece en ambos textos en el mismo orden,\n",
    "    #            aunque no necesariamente de forma contigua.\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "scores = scorer.score(txt, resumen)\n",
    "\n",
    "\n",
    "print(f'Rouge 1\\n\\tPrecision : {round(scores[\"rouge1\"][0],2)}\\n\\tRecall : {round(scores[\"rouge1\"][1],2)}\\n\\tF1 Score : {round(scores[\"rouge1\"][2],2)}')\n",
    "print(f'Rouge 2\\n\\tPrecision : {round(scores[\"rouge2\"][0],2)}\\n\\tRecall : {round(scores[\"rouge2\"][1],2)}\\n\\tF1 Score : {round(scores[\"rouge2\"][2],2)}')\n",
    "print(f'Rouge L\\n\\tPrecision : {round(scores[\"rougeL\"][0],2)}\\n\\tRecall : {round(scores[\"rougeL\"][1],2)}\\n\\tF1 Score : {round(scores[\"rougeL\"][2],2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision: cuántas palabras del resumen coinciden con el texto original\n",
    "- Recall: cuántas palabras del texto original están cubiertas por el resumen\n",
    "- F1 Score: balance entre la precisión y el recall\n",
    "\n",
    "Analisis metricas:\n",
    "\n",
    " - Rouge 1: Se observa que el modelo utiliza el 96% de las palabras en el resumen existen en el texto original y 29% de las palabras del texto original se encuentran en el resumen.\n",
    " - Rouge 2: Se observa que el modelo utilzia el 88% de los bigramas del resumen existen en el texto original y 27% de los bigramas del texto original se encuentran en el resumen.\n",
    " - Rouge L: Se observa que el modelo utilzia el 96% de las secuencias mas largas del resumen existen en el texto original y 29% de las secuencias mas largas del texto original se encuentran en el resumen.\n",
    "\n",
    "En este ejemplo, se puede concluir que este modelo puede ser utilizado para el uso de generacion de resumenes. A continuacion, se realizara una prueba con un texto de mayor longitud y complejidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tokens: 1005\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer_bart.encode(texto_grande[5000:10000])\n",
    "print(f\"Número de tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Florence-2 is capable of performing a variety of tasks, such as object detection, captioning, and grounding, all within a single model governed by a uniform set of parameters. The pre-trained Florence-2 backbone enhances performance on downstream tasks, e.g. COCO object detection and instance segmentation, and ADE20K semantic segmentation.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incremento el maximo del output\n",
    "summarizer_bart(texto_grande[5000:10000],max_length=600, min_length=30, do_sample=False)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si introduzco mas de los tokens que el modelo permite, da error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigBirdPegasus - Numero de tokens 4096 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n",
    "\n",
    "model_Pegasus_OF = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\",attention_type=\"original_full\",block_size=16, num_random_blocks=2)\n",
    "model_Pegasus_SparseAttention = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\",block_size=16, num_random_blocks=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> we introduce a novel foundation model with a unified prompt - based representation for a variety of computer vision and vision tasks .</s>']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(txt, return_tensors='pt')\n",
    "prediction_OF = model_Pegasus_OF.generate(**inputs,)\n",
    "prediction_OF = tokenizer.batch_decode(prediction_OF)\n",
    "prediction_OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge 1\n",
      "\tPrecision : 0.91\n",
      "\tRecall : 0.12\n",
      "\tF1 Score : 0.22\n",
      "Rouge 2\n",
      "\tPrecision : 0.82\n",
      "\tRecall : 0.11\n",
      "\tF1 Score : 0.19\n",
      "Rouge L\n",
      "\tPrecision : 0.91\n",
      "\tRecall : 0.12\n",
      "\tF1 Score : 0.22\n"
     ]
    }
   ],
   "source": [
    "scores = scorer.score(txt, str(prediction_OF))\n",
    "\n",
    "print(f'Rouge 1\\n\\tPrecision : {round(scores[\"rouge1\"][0],2)}\\n\\tRecall : {round(scores[\"rouge1\"][1],2)}\\n\\tF1 Score : {round(scores[\"rouge1\"][2],2)}')\n",
    "print(f'Rouge 2\\n\\tPrecision : {round(scores[\"rouge2\"][0],2)}\\n\\tRecall : {round(scores[\"rouge2\"][1],2)}\\n\\tF1 Score : {round(scores[\"rouge2\"][2],2)}')\n",
    "print(f'Rouge L\\n\\tPrecision : {round(scores[\"rougeL\"][0],2)}\\n\\tRecall : {round(scores[\"rougeL\"][1],2)}\\n\\tF1 Score : {round(scores[\"rougeL\"][2],2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> in this paper , we introduce largeshot-@xmath0 , a novel computer vision model with a unified prompt model capabilities .<n> largeshot-@xmath0 is a sequence-@xmath0 model , where @xmath1 is the number of training frames , @xmath2 is the number of test frames , and @xmath3 is the number of test images .<n> largeshot-@xmath0 is a sequence-@xmath0 learning model , where @xmath1 is the number of training frames , @xmath2 is the number of test frames , and @xmath3 is the number of test images .<n> largeshot-@xmath0 is a sequence-@xmath0 learning model , where @xmath1 is the number of training frames , @xmath2 is the number of test frames , and @xmath3 is the number of test images .<n> largeshot-@xmath0 is a sequence-@xmath0 learning model , where @xmath1 is the number of training frames , @xmath2 is the number of test frames , and @xmath3 is the number']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(txt, return_tensors='pt')\n",
    "prediction_Sparseattention = model_Pegasus_SparseAttention.generate(**inputs)\n",
    "prediction_Sparseattention = tokenizer.batch_decode(prediction_Sparseattention)\n",
    "prediction_Sparseattention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge 1\n",
      "\tPrecision : 0.27\n",
      "\tRecall : 0.22\n",
      "\tF1 Score : 0.24\n",
      "Rouge 2\n",
      "\tPrecision : 0.06\n",
      "\tRecall : 0.05\n",
      "\tF1 Score : 0.06\n",
      "Rouge L\n",
      "\tPrecision : 0.19\n",
      "\tRecall : 0.16\n",
      "\tF1 Score : 0.17\n"
     ]
    }
   ],
   "source": [
    "scores = scorer.score(txt, str(prediction_Sparseattention))\n",
    "\n",
    "print(f'Rouge 1\\n\\tPrecision : {round(scores[\"rouge1\"][0],2)}\\n\\tRecall : {round(scores[\"rouge1\"][1],2)}\\n\\tF1 Score : {round(scores[\"rouge1\"][2],2)}')\n",
    "print(f'Rouge 2\\n\\tPrecision : {round(scores[\"rouge2\"][0],2)}\\n\\tRecall : {round(scores[\"rouge2\"][1],2)}\\n\\tF1 Score : {round(scores[\"rouge2\"][2],2)}')\n",
    "print(f'Rouge L\\n\\tPrecision : {round(scores[\"rougeL\"][0],2)}\\n\\tRecall : {round(scores[\"rougeL\"][1],2)}\\n\\tF1 Score : {round(scores[\"rougeL\"][2],2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el rendimiento de BigBird con el tipo de atención original_full se asemeja al de BART, aunque con resultados ligeramente inferiores. Por otro lado, al utilizar el tipo de atención sparse, se obtiene la capacidad de manejar una mayor cantidad de tokens, lo que podría ser útil para reconstruir los documentos mediante plantillas. Sin embargo, esto conlleva un aumento significativo en la complejidad programática y, por ende, un mayor consumo computacional. Este es uno de los principales desafíos del proyecto, por lo que, de momento, no es una orientación viable. En consecuencia, se concluye que, a priori, el modelo BART es más adecuado para las necesidades de Lervis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
