{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "source = \"TEST_OCR.pdf\"  # document per local path or URL\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(source)\n",
    "print(result.document.export_to_markdown())  # output: \"## Docling Technical Report[...]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.utils.export import generate_multimodal_pages\n",
    "from docling.utils.utils import create_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_RESOLUTION_SCALE = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    input_doc_path = Path(\"TEST_OCR.pdf\")\n",
    "    output_dir = Path(\"scratch\")\n",
    "\n",
    "    # Important: For operating with page images, we must keep them, otherwise the DocumentConverter\n",
    "    # will destroy them for cleaning up memory.\n",
    "    # This is done by setting AssembleOptions.images_scale, which also defines the scale of images.\n",
    "    # scale=1 correspond of a standard 72 DPI image\n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE\n",
    "    pipeline_options.generate_page_images = True\n",
    "\n",
    "    doc_converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    conv_res = doc_converter.convert(input_doc_path)\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    rows = []\n",
    "    for (\n",
    "        content_text,\n",
    "        content_md,\n",
    "        content_dt,\n",
    "        page_cells,\n",
    "        page_segments,\n",
    "        page,\n",
    "    ) in generate_multimodal_pages(conv_res):\n",
    "\n",
    "        dpi = page._default_image_scale * 72\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"document\": conv_res.input.file.name,\n",
    "                \"hash\": conv_res.input.document_hash,\n",
    "                \"page_hash\": create_hash(\n",
    "                    conv_res.input.document_hash + \":\" + str(page.page_no - 1)\n",
    "                ),\n",
    "                \"image\": {\n",
    "                    \"width\": page.image.width,\n",
    "                    \"height\": page.image.height,\n",
    "                    \"bytes\": page.image.tobytes(),\n",
    "                },\n",
    "                \"cells\": page_cells,\n",
    "                \"contents\": content_text,\n",
    "                \"contents_md\": content_md,\n",
    "                \"contents_dt\": content_dt,\n",
    "                \"segments\": page_segments,\n",
    "                \"extra\": {\n",
    "                    \"page_num\": page.page_no + 1,\n",
    "                    \"width_in_points\": page.size.width,\n",
    "                    \"height_in_points\": page.size.height,\n",
    "                    \"dpi\": dpi,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Generate one parquet from all documents\n",
    "    df = pd.json_normalize(rows)\n",
    "    now = datetime.datetime.now()\n",
    "    output_filename = output_dir / f\"multimodal_{now:%Y-%m-%d_%H%M%S}.parquet\"\n",
    "    df.to_parquet(output_filename)\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    _log.info(\n",
    "        f\"Document converted and multimodal pages generated in {end_time:.2f} seconds.\"\n",
    "    )\n",
    "\n",
    "    # This block demonstrates how the file can be opened with the HF datasets library\n",
    "    # from datasets import Dataset\n",
    "    # from PIL import Image\n",
    "    # multimodal_df = pd.read_parquet(output_filename)\n",
    "\n",
    "    # # Convert pandas DataFrame to Hugging Face Dataset and load bytes into image\n",
    "    # dataset = Dataset.from_pandas(multimodal_df)\n",
    "    # def transforms(examples):\n",
    "    #     examples[\"image\"] = Image.frombytes('RGB', (examples[\"image.width\"], examples[\"image.height\"]), examples[\"image.bytes\"], 'raw')\n",
    "    #     return examples\n",
    "    # dataset = dataset.map(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "Fetching 9 files: 100%|██████████| 9/9 [00:00<?, ?it/s]\n",
      "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "INFO:docling.pipeline.base_pipeline:Processing document TEST_OCR.pdf\n",
      "INFO:docling.document_converter:Finished converting document TEST_OCR.pdf in 93.55 sec.\n",
      "INFO:__main__:Document converted and multimodal pages generated in 95.20 seconds.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.5.1 available.\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "multimodal_df = pd.read_parquet(\"scratch/multimodal_2024-12-04_171052.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 35/35 [00:03<00:00,  9.31 examples/s] \n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrame to Hugging Face Dataset and load bytes into image\n",
    "dataset = Dataset.from_pandas(multimodal_df)\n",
    "def transforms(examples):\n",
    "         examples[\"image\"] = Image.frombytes('RGB', (examples[\"image.width\"], examples[\"image.height\"]), examples[\"image.bytes\"], 'raw')\n",
    "         return examples\n",
    "\n",
    "dataset = dataset.map(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'hash', 'page_hash', 'cells', 'contents', 'contents_md', 'contents_dt', 'segments', 'image.width', 'image.height', 'image.bytes', 'extra.page_num', 'extra.width_in_points', 'extra.height_in_points', 'extra.dpi', 'image'],\n",
       "    num_rows: 35\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bbox': [0.5034954095977584, 0.30377120201033775, 0.8892027412364686, 0.5058443088724156], 'data': [], 'index_in_doc': 13, 'label': 'picture', 'text': 'Figure 1. We aim to build a vision foundation model to enable extensive perception capabilities including spatial hierarchy and semantic granularity. To achieve this, a single unified model Florence-2 is pre-trained on our FLD-5B dataset encompassing a total of 5.4B comprehensive annotations across 126M images, which are collected by our Florence data engine.'}\n"
     ]
    }
   ],
   "source": [
    "for segment in dataset[0][\"segments\"]:\n",
    "    if segment['label'] == 'picture':\n",
    "        bbox = segment['bbox']\n",
    "        print(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height = dataset[0]['image'].size\n",
    "\n",
    "# Convertir coordenadas normalizadas a píxeles\n",
    "left = int(bbox[0] * image_width)\n",
    "top = int(bbox[1] * image_height)\n",
    "right = int(bbox[2] * image_width)\n",
    "bottom = int(bbox[3] * image_height)\n",
    "\n",
    "cropped_image = dataset[0]['image'].crop((left, top, right, bottom))\n",
    "\n",
    "# Guardar o mostrar la región recortada\n",
    "cropped_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
